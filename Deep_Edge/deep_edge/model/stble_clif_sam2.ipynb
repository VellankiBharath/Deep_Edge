{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import clip\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2  # OpenCV for image processing\n",
    "import sam  # Assuming you have installed SAM2 correctly\n",
    "import matplotlib.pyplot as plt\n",
    "import base64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_base64(image):\n",
    "    from io import BytesIO\n",
    "    buffered = BytesIO()\n",
    "    image.save(buffered, format=\"PNG\")\n",
    "    return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3ea4cc4e0c44fd4ab7e7f89893c10e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0820f17bc32a4dce88afbf7946365023",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set up Stable Diffusion\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\")\n",
    "pipe = pipe.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Generate an image based on the prompt\n",
    "prompt = \"a mom holding a baby\"\n",
    "image = pipe(prompt).images[0]\n",
    "image.save(\"generated_image.png\")  # Save the image for analysis\n",
    "image.show()  # Show the generated image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: 'landscape', Confidence Score: 0.1394\n",
      "Prompt: 'mountains', Confidence Score: 0.1671\n",
      "Prompt: 'sunset', Confidence Score: 0.0038\n",
      "Prompt: 'river', Confidence Score: 0.6696\n",
      "Prompt: 'sky', Confidence Score: 0.0201\n"
     ]
    }
   ],
   "source": [
    "# Set up CLIP\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Preprocess the generated image for CLIP\n",
    "image_clip = preprocess(image).unsqueeze(0).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define possible text descriptions for analysis\n",
    "text_prompts = [\"landscape\", \"mountains\", \"sunset\", \"river\", \"sky\"]\n",
    "text_inputs = clip.tokenize(text_prompts).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Analyze the image using CLIP\n",
    "with torch.no_grad():\n",
    "    image_features = model.encode_image(image_clip)\n",
    "    text_features = model.encode_text(text_inputs)\n",
    "\n",
    "    # Calculate similarity scores\n",
    "    logits_per_image, logits_per_text = image_features @ text_features.T, text_features @ image_features.T\n",
    "    probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n",
    "# Collect CLIP results into a dictionary\n",
    "clip_results = {text: float(probs[0][i]) for i, text in enumerate(text_prompts)}\n",
    "# Print the results from CLIP\n",
    "for i, text in enumerate(text_prompts):\n",
    "    print(f\"Prompt: '{text}', Confidence Score: {probs[0][i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda\\.conda\\Lib\\site-packages\\segment_anything\\build_sam.py:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(f)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from segment_anything import build_sam, SamPredictor\n",
    "from segment_anything import SamPredictor, sam_model_registry\n",
    "sam_checkpoint = \"checkpoints/sam_vit_h_4b8939.pth\"  # Path to your checkpoint file\n",
    "# Check if you have a GPU and set the device accordingly\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load the SAM model with the appropriate checkpoint\n",
    "sam_checkpoint = \"sam_vit_h_4b8939.pth\"  # Path to SAM model checkpoint\n",
    "sam_model = sam_model_registry[\"vit_h\"](checkpoint=sam_checkpoint).to(device)\n",
    "\n",
    "# Initialize the SAM predictor\n",
    "predictor = SamPredictor(sam_model)\n",
    "\n",
    "# Load and preprocess the image\n",
    "image_path = \"generated_image.png\"  # Path to the image you want to segment\n",
    "sam_image = cv2.imread(image_path)\n",
    "sam_image = cv2.cvtColor(sam_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Set the image in the predictor\n",
    "predictor.set_image(sam_image)\n",
    "\n",
    "# You can now interact with the SAM model to get masks (e.g., using points)\n",
    "input_point = np.array([[500, 375]])  # Example point for instance segmentation\n",
    "input_label = np.array([1])\n",
    "\n",
    "masks, scores, logits = predictor.predict(\n",
    "    point_coords=input_point,\n",
    "    point_labels=input_label,\n",
    "    multimask_output=True  # Enable multi-mask output for different options\n",
    ")\n",
    "\n",
    "# Display the mask\n",
    "for idx, mask in enumerate(masks):\n",
    "    plt.subplot(1, len(masks), idx + 1)\n",
    "    plt.imshow(mask, cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert masks and scores to JSON-compatible format (lists)\n",
    "masks_list = [mask.tolist() for mask in masks]\n",
    "scores_list = scores.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_save = {\n",
    "    \"generated_image\": image_to_base64(image),  # Convert image to base64 string\n",
    "    \"clip_results\": clip_results,  # CLIP analysis results (confidence scores)\n",
    "    \"sam_masks\": masks_list,  # SAM2 segmentation masks as lists\n",
    "    \"sam_scores\": scores_list  # SAM2 segmentation scores as lists\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('stble_clif_sam2.pickle', 'wb') as f:\n",
    "    pickle.dump(data_to_save,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Save everything to a JSON file\n",
    "with open('stble_clif_sam2.json', 'w') as f:\n",
    "    json.dump(data_to_save, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
